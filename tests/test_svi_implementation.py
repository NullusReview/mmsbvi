"""
SVIå®ç°æµ‹è¯• / SVI Implementation Test
=================================

æµ‹è¯•SVIå˜åˆ†æ¨æ–­çš„æ•°å­¦å®ç°æ­£ç¡®æ€§ã€‚
Test the mathematical correctness of SVI variational inference implementation.
"""

import pytest
import jax
import jax.numpy as jnp
import numpy as np
from jax import random
import sys
import pathlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ / add project root to path
root_dir = pathlib.Path(__file__).resolve().parents[1]
if str(root_dir) not in sys.path:
    sys.path.append(str(root_dir))

# ç¡®ä¿JAXé…ç½® / ensure JAX configuration
jax.config.update('jax_enable_x64', True)

from src.baselines.svi import DuffingSVISmoother


def generate_test_data(key: jax.random.PRNGKey, T: int = 20) -> dict:
    """
    ç”Ÿæˆæµ‹è¯•ç”¨çš„Duffingç³»ç»Ÿè½¨è¿¹ / Generate test Duffing system trajectory
    
    Args:
        key: éšæœºå¯†é’¥ / random key
        T: æ—¶é—´æ­¥æ•° / number of time steps
        
    Returns:
        data: åŒ…å«çœŸå®çŠ¶æ€å’Œè§‚æµ‹çš„å­—å…¸ / dictionary containing true states and observations
    """
    dt = 0.05
    duffing_mu = 0.35
    duffing_sigma = 0.3
    obs_noise_std = 0.05
    
    # åˆå§‹çŠ¶æ€ / initial state
    x0 = jnp.array([0.5, 0.0])  # [ä½ç½®, é€Ÿåº¦]
    
    # ç”ŸæˆçœŸå®è½¨è¿¹ / generate true trajectory
    states = [x0]
    key_seq = random.split(key, T)
    
    for t in range(1, T):
        prev_state = states[-1]
        x, v = prev_state[0], prev_state[1]
        
        # DuffingåŠ¨æ€ + å™ªå£° / Duffing dynamics + noise
        dx = v * dt
        dv = (-x**3 + x - duffing_mu * v) * dt + duffing_sigma * jnp.sqrt(dt) * random.normal(key_seq[t])
        
        next_state = prev_state + jnp.array([dx, dv])
        states.append(next_state)
    
    true_states = jnp.array(states)
    
    # ç”Ÿæˆè§‚æµ‹ï¼ˆä½ç½® + å™ªå£°ï¼‰/ generate observations (position + noise)
    obs_key = random.split(key, T)[0]
    obs_noise = obs_noise_std * random.normal(obs_key, (T,))
    observations = true_states[:, 0] + obs_noise
    
    return {
        'x': true_states,
        'y': observations,
        'dt': dt,
        'T': T
    }


def test_svi_initialization():
    """æµ‹è¯•SVIå¹³æ»‘å™¨åˆå§‹åŒ– / Test SVI smoother initialization"""
    smoother = DuffingSVISmoother(
        dt=0.05,
        duffing_mu=0.35,
        duffing_sigma=0.3,
        learning_rate=0.01,
        max_iterations=100
    )
    
    # æ£€æŸ¥å‚æ•°è®¾ç½® / check parameter settings
    assert smoother.dt == 0.05
    assert smoother.duffing_mu == 0.35
    assert smoother.duffing_sigma == 0.3
    assert smoother.learning_rate == 0.01
    assert smoother.max_iterations == 100
    
    # æ£€æŸ¥åæ–¹å·®çŸ©é˜µ / check covariance matrices
    assert smoother.Q.shape == (2, 2)
    assert smoother.R > 0
    
    print("âœ… SVIåˆå§‹åŒ–æµ‹è¯•é€šè¿‡")


def test_svi_dynamics_mean():
    """æµ‹è¯•DuffingåŠ¨æ€å‡å€¼è®¡ç®— / Test Duffing dynamics mean computation"""
    smoother = DuffingSVISmoother(dt=0.05, duffing_mu=0.35)
    
    # æµ‹è¯•çŠ¶æ€ / test state
    state = jnp.array([1.0, 0.5])  # [x=1.0, v=0.5]
    
    # è®¡ç®—ä¸‹ä¸€æ—¶åˆ»å‡å€¼ / compute next time step mean
    next_mean = smoother._dynamics_mean_impl(state)
    
    # é¢„æœŸç»“æœ / expected result
    x, v = state[0], state[1]
    expected_dx = v * smoother.dt
    expected_dv = (-x**3 + x - smoother.duffing_mu * v) * smoother.dt
    expected_next = state + jnp.array([expected_dx, expected_dv])
    
    # éªŒè¯ç»“æœ / verify result
    assert jnp.allclose(next_mean, expected_next, atol=1e-10)
    
    print("âœ… DuffingåŠ¨æ€å‡å€¼è®¡ç®—æµ‹è¯•é€šè¿‡")


def test_svi_log_probabilities():
    """æµ‹è¯•å¯¹æ•°æ¦‚ç‡è®¡ç®— / Test log probability computations"""
    smoother = DuffingSVISmoother(
        dt=0.05,
        duffing_mu=0.35,
        duffing_sigma=0.3,
        process_noise_scale=0.1,
        obs_noise_std=0.05
    )
    
    # æµ‹è¯•è½¬ç§»æ¦‚ç‡ / test transition probability
    # ä½¿ç”¨æ›´åˆç†çš„çŠ¶æ€è½¬ç§»ï¼šä»åŠ¨æ€æ¨¡å‹é¢„æµ‹çš„çŠ¶æ€é™„è¿‘
    x_prev = jnp.array([0.5, 0.2])
    predicted_mean = smoother._dynamics_mean_impl(x_prev)
    # åœ¨é¢„æµ‹å‡å€¼é™„è¿‘æ·»åŠ å°æ‰°åŠ¨
    x_curr = predicted_mean + jnp.array([0.001, 0.001])  # å°æ‰°åŠ¨
    
    log_trans_prob = smoother._log_transition_prob_impl(x_curr, x_prev)
    print(f"è½¬ç§»æ¦‚ç‡æµ‹è¯•: prev={x_prev}, curr={x_curr}, predicted={predicted_mean}, log_prob={log_trans_prob}")
    assert jnp.isfinite(log_trans_prob)
    # æ³¨æ„ï¼šæ¦‚ç‡å¯†åº¦å¯ä»¥å¤§äº1ï¼Œæ‰€ä»¥å¯¹æ•°æ¦‚ç‡å¯ä»¥ä¸ºæ­£ / Note: probability density can be > 1, so log prob can be positive
    
    # æµ‹è¯•è§‚æµ‹æ¦‚ç‡ / test observation probability
    state = jnp.array([0.5, 0.2])
    observation = state[0] + 0.001  # ä½ç½®è§‚æµ‹åŠ å°å™ªå£°
    
    log_obs_prob = smoother._log_observation_prob_impl(observation, state)
    print(f"è§‚æµ‹æ¦‚ç‡æµ‹è¯•: state={state}, obs={observation}, log_prob={log_obs_prob}")
    assert jnp.isfinite(log_obs_prob)
    # åŒæ ·ï¼Œè§‚æµ‹æ¦‚ç‡å¯†åº¦ä¹Ÿå¯ä»¥å¤§äº1 / Similarly, observation probability density can be > 1
    
    print("âœ… å¯¹æ•°æ¦‚ç‡è®¡ç®—æµ‹è¯•é€šè¿‡")


def test_svi_variational_sampling():
    """æµ‹è¯•å˜åˆ†åˆ†å¸ƒé‡‡æ · / Test variational distribution sampling"""
    smoother = DuffingSVISmoother(n_samples=10)
    
    T = 5
    means = jnp.ones((T, 2)) * 0.5
    log_stds = jnp.log(jnp.ones((T, 2)) * 0.1)
    
    from src.baselines.svi.svi_smoother import SVIParams
    params = SVIParams(means=means, log_stds=log_stds)
    
    key = random.PRNGKey(42)
    samples = smoother._sample_from_variational(params, key)
    
    # æ£€æŸ¥é‡‡æ ·å½¢çŠ¶ / check sample shape
    assert samples.shape == (smoother.n_samples, T, 2)
    
    # æ£€æŸ¥é‡‡æ ·åˆ†å¸ƒï¼ˆå¤§è‡´ï¼‰/ check sample distribution (roughly)
    sample_means = jnp.mean(samples, axis=0)
    sample_stds = jnp.std(samples, axis=0)
    
    # é‡‡æ ·å‡å€¼åº”è¯¥æ¥è¿‘å˜åˆ†å‡å€¼ / sample means should be close to variational means
    assert jnp.allclose(sample_means, means, atol=0.2)
    
    print("âœ… å˜åˆ†åˆ†å¸ƒé‡‡æ ·æµ‹è¯•é€šè¿‡")


def test_svi_elbo_computation():
    """æµ‹è¯•ELBOè®¡ç®— / Test ELBO computation"""
    smoother = DuffingSVISmoother(
        dt=0.05,
        n_samples=20,
        max_iterations=50
    )
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ® / generate test data
    key = random.PRNGKey(123)
    test_data = generate_test_data(key, T=10)
    observations = test_data['y']
    
    T = len(observations)
    
    # åˆ›å»ºæµ‹è¯•å˜åˆ†å‚æ•° / create test variational parameters
    means = jnp.zeros((T, 2))
    log_stds = jnp.log(jnp.ones((T, 2)) * 0.2)
    
    from src.baselines.svi.svi_smoother import SVIParams
    params = SVIParams(means=means, log_stds=log_stds)
    
    # è®¡ç®—ELBO / compute ELBO
    key_elbo = random.PRNGKey(456)
    elbo = smoother._compute_elbo_impl(params, observations, key_elbo)
    
    # ELBOåº”è¯¥æ˜¯æœ‰é™çš„ / ELBO should be finite
    assert jnp.isfinite(elbo)
    
    print(f"âœ… ELBOè®¡ç®—æµ‹è¯•é€šè¿‡ï¼ŒELBOå€¼: {elbo:.4f}")


def test_svi_smoothing_basic():
    """æµ‹è¯•SVIå¹³æ»‘åŸºæœ¬åŠŸèƒ½ / Test SVI smoothing basic functionality"""
    print("\n=== å¼€å§‹SVIå¹³æ»‘åŸºæœ¬åŠŸèƒ½æµ‹è¯• ===")
    
    # åˆ›å»ºSVIå¹³æ»‘å™¨ï¼ˆè¾ƒå°çš„å‚æ•°ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰/ create SVI smoother with small parameters for fast testing
    smoother = DuffingSVISmoother(
        dt=0.05,
        duffing_mu=0.35,
        duffing_sigma=0.3,
        learning_rate=0.02,
        n_samples=10,
        max_iterations=50,
        convergence_tol=1e-4
    )
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ® / generate test data
    key = random.PRNGKey(789)
    test_data = generate_test_data(key, T=15)
    
    observations = jnp.array(test_data['y'])
    true_states = test_data['x']
    
    print(f"æµ‹è¯•æ•°æ®: T={len(observations)}, è§‚æµ‹èŒƒå›´: [{jnp.min(observations):.3f}, {jnp.max(observations):.3f}]")
    
    # æ‰§è¡ŒSVIå¹³æ»‘ / perform SVI smoothing
    initial_mean = jnp.array([observations[0], 0.0])
    initial_cov = jnp.eye(2) * 1.0
    
    key_smooth = random.PRNGKey(101112)
    result = smoother.smooth(
        observations=observations,
        initial_mean=initial_mean,
        initial_cov=initial_cov,
        key=key_smooth
    )
    
    # æ£€æŸ¥ç»“æœç»“æ„ / check result structure
    assert hasattr(result, 'means')
    assert hasattr(result, 'log_stds')
    assert hasattr(result, 'total_log_likelihood')
    assert hasattr(result, 'elbo')
    
    # æ£€æŸ¥ç»“æœå½¢çŠ¶ / check result shapes
    assert result.means.shape == (len(observations), 2)
    assert result.log_stds.shape == (len(observations), 2)
    assert jnp.isfinite(result.total_log_likelihood)
    assert jnp.isfinite(result.elbo)
    
    # æå–ä¼°è®¡ / extract estimates
    estimates = smoother.extract_estimates(result)
    
    # æ£€æŸ¥ä¼°è®¡ç»“æ„ / check estimates structure
    assert 'x_mean' in estimates
    assert 'x_std' in estimates
    assert 'v_mean' in estimates
    assert 'v_std' in estimates
    
    # è®¡ç®—RMSE / compute RMSE
    x_true = true_states[:, 0]
    x_pred = estimates['x_mean']
    rmse = float(jnp.sqrt(jnp.mean((x_true - x_pred)**2)))
    
    print(f"SVIç»“æœ:")
    print(f"  RMSE: {rmse:.6f}")
    print(f"  ELBO: {result.elbo:.4f}")
    print(f"  æ€»å¯¹æ•°ä¼¼ç„¶: {result.total_log_likelihood:.4f}")
    print(f"  ä½ç½®ä¼°è®¡èŒƒå›´: [{jnp.min(x_pred):.3f}, {jnp.max(x_pred):.3f}]")
    print(f"  ä¸ç¡®å®šæ€§èŒƒå›´: [{jnp.min(estimates['x_std']):.3f}, {jnp.max(estimates['x_std']):.3f}]")
    
    # åŸºæœ¬åˆç†æ€§æ£€æŸ¥ / basic sanity checks
    assert rmse < 1.0  # RMSEåº”è¯¥åˆç†
    assert jnp.all(estimates['x_std'] > 0)  # æ ‡å‡†å·®åº”è¯¥ä¸ºæ­£
    assert jnp.all(jnp.isfinite(estimates['x_mean']))  # ä¼°è®¡åº”è¯¥æœ‰é™
    
    print("âœ… SVIå¹³æ»‘åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    return {
        'rmse': rmse,
        'elbo': result.elbo,
        'total_log_likelihood': result.total_log_likelihood,
        'estimates': estimates,
        'true_states': true_states,
        'observations': observations
    }


def test_svi_convergence():
    """æµ‹è¯•SVIæ”¶æ•›æ€§ / Test SVI convergence"""
    print("\n=== å¼€å§‹SVIæ”¶æ•›æ€§æµ‹è¯• ===")
    
    # ä½¿ç”¨æ›´å¤šè¿­ä»£æµ‹è¯•æ”¶æ•› / use more iterations to test convergence
    smoother = DuffingSVISmoother(
        dt=0.05,
        learning_rate=0.01,
        n_samples=15,
        max_iterations=200,
        convergence_tol=1e-5
    )
    
    # ç”Ÿæˆç®€å•æµ‹è¯•æ•°æ® / generate simple test data
    key = random.PRNGKey(131415)
    test_data = generate_test_data(key, T=10)
    
    observations = jnp.array(test_data['y'])
    
    # è¿è¡ŒSVI / run SVI
    result = smoother.smooth(
        observations=observations,
        initial_mean=jnp.array([observations[0], 0.0]),
        initial_cov=jnp.eye(2) * 0.5,
        key=random.PRNGKey(161718)
    )
    
    # æ£€æŸ¥ELBOæ˜¯å¦æœ‰é™ä¸”åˆç† / check if ELBO is finite and reasonable
    assert jnp.isfinite(result.elbo)
    assert result.elbo > -1000  # ä¸åº”è¯¥å¤ªè´Ÿ
    
    print(f"æ”¶æ•›æµ‹è¯•ç»“æœ: ELBO={result.elbo:.4f}")
    print("âœ… SVIæ”¶æ•›æ€§æµ‹è¯•é€šè¿‡")


def main():
    """è¿è¡Œæ‰€æœ‰SVIæµ‹è¯• / Run all SVI tests"""
    print("ğŸ§ª å¼€å§‹SVIå®ç°æµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    try:
        # åŸºç¡€æµ‹è¯• / basic tests
        test_svi_initialization()
        test_svi_dynamics_mean()
        test_svi_log_probabilities()
        test_svi_variational_sampling()
        test_svi_elbo_computation()
        
        # åŠŸèƒ½æµ‹è¯• / functional tests
        result = test_svi_smoothing_basic()
        test_svi_convergence()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰SVIæµ‹è¯•é€šè¿‡ï¼")
        print("=" * 50)
        
        # è¿”å›æµ‹è¯•ç»“æœç”¨äºåˆ†æ / return test results for analysis
        return result
        
    except Exception as e:
        print(f"\nâŒ SVIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()